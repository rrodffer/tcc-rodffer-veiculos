{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analise e Previsão de Acidentes de Transito Fatais em Rodovias Federais Brasileiras\n",
    "\n",
    "Rayron Ferreira\n",
    "\n",
    "05/03/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivação\n",
    "\n",
    "- impacto economico\n",
    "- impacto social\n",
    "- quanto custa por ano os acidentes ?\n",
    "- qual o impacto com acidentes fatais ?\n",
    "- reduzir o numero de acidentes de transito e esses impactos\n",
    "- mitigar/evitar condicoes nas estradas que causam acidentes fatais\n",
    "- previsao de acidente e gravidade do acidente\n",
    "- podemos identificar os padroes de como os acidentes fatais ocorrem e os principais fatores?\n",
    "- alocar melhor os recursos financeiros e humanos nas rodovias federais buscando evitar acidentes fatais\n",
    "\n",
    "### Objetivos\n",
    "\n",
    "\n",
    "### Analise\n",
    "\n",
    "### Palavras-chave\n",
    "\n",
    "### Sobre o Dataset\n",
    "\n",
    "### Agradecimentos e Colaborações  \n",
    "\n",
    "### Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização e pre-processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# from pymongo import MongoClient\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, classification_report, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import learning_curve, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação das Variáveis\n",
    "\n",
    "**Atributos de Identificação**\n",
    "* **id**: Identificador do acidente.\n",
    "* **pesid**: Identificador da pessoa envolvida.\n",
    "* **id_veiculo**: Identificador do veículo envolvido.\n",
    "\n",
    "**Atributos de Período do Dia**\n",
    "* **data_inversa**: Data da ocorrência.\n",
    "* **dia_semana**: Dia da semana da ocorrência.\n",
    "* **horario**: Horário da ocorrência.\n",
    "* **fase_dia**: Fase do dia no momento do acidente.\n",
    "\n",
    "**Atributos de Endereço**\n",
    "* **uf**: Unidade da Federação.\n",
    "* **br**: Identificador da BR.\n",
    "* **km**: Quilômetro do acidente.\n",
    "* **municipio**: Nome do município.\n",
    "* **latitude**: Latitude do local do acidente.\n",
    "* **longitude**: Longitude do local do acidente.\n",
    "* **regional**: Superintendência regional da PRF.\n",
    "* **delegacia**: Delegacia da PRF.\n",
    "* **uop**: Unidade operacional da PRF.\n",
    "\n",
    "**Atributos de Tráfego**\n",
    "* **sentido_via**: Sentido da via.\n",
    "* **tipo_pista**: Tipo de pista.\n",
    "* **tracado_via**: Descrição do traçado da via.\n",
    "* **uso_solo**: Características do local do acidente (urbano/rural).\n",
    "\n",
    "**Atributos Climáticos**\n",
    "* **condição_meteorologica**: Condição meteorológica no momento do acidente.\n",
    "\n",
    "**Atributos de Causa e Tipo de Acidente**\n",
    "* **causa_principal**: Causa principal do acidente.\n",
    "* **causa_acidente**: Causa presumível do acidente.\n",
    "* **ordem_tipo_acidente**: Sequência de eventos no acidente.\n",
    "* **tipo_acidente**: Tipo de acidente.\n",
    "* **classificação_acidente**: Gravidade do acidente.\n",
    "\n",
    "**Atributos de Veículo**\n",
    "* **tipo_veiculo**: Tipo de veículo.\n",
    "* **marca**: Marca do veículo.\n",
    "* **ano_fabricacao_veiculo**: Ano de fabricação do veículo.\n",
    "\n",
    "**Atributos de Pessoas Envolvidas**\n",
    "* **tipo_envolvido**: Tipo de envolvido no acidente.\n",
    "* **estado_fisico**: Condição física do envolvido.\n",
    "* **idade**: Idade do envolvido.\n",
    "* **sexo**: Sexo do envolvido.\n",
    "\n",
    "**Atributos de Vítimas**\n",
    "* **ilesos**: Identifica se o envolvido foi ileso.\n",
    "* **feridos_leves**: Identifica se o envolvido foi ferido leve.\n",
    "* **feridos_graves**: Identifica se o envolvido foi ferido grave.\n",
    "* **mortos**: Identifica se o envolvido foi morto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 977884 entries, 0 to 977883\n",
      "Data columns (total 32 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   data_inversa            977884 non-null  object\n",
      " 1   dia_semana              977884 non-null  object\n",
      " 2   horario                 977884 non-null  object\n",
      " 3   uf                      977884 non-null  object\n",
      " 4   br                      977884 non-null  int64 \n",
      " 5   km                      977884 non-null  object\n",
      " 6   municipio               977884 non-null  object\n",
      " 7   causa_acidente          977884 non-null  object\n",
      " 8   tipo_acidente           977884 non-null  object\n",
      " 9   classificacao_acidente  977884 non-null  object\n",
      " 10  fase_dia                977884 non-null  object\n",
      " 11  sentido_via             977884 non-null  object\n",
      " 12  condicao_metereologica  977884 non-null  object\n",
      " 13  tipo_pista              977884 non-null  object\n",
      " 14  tracado_via             977884 non-null  object\n",
      " 15  uso_solo                977884 non-null  object\n",
      " 16  id_veiculo              977884 non-null  int64 \n",
      " 17  tipo_veiculo            977884 non-null  object\n",
      " 18  marca                   977884 non-null  object\n",
      " 19  ano_fabricacao_veiculo  977884 non-null  int64 \n",
      " 20  tipo_envolvido          977884 non-null  object\n",
      " 21  estado_fisico           977884 non-null  object\n",
      " 22  idade                   977884 non-null  int64 \n",
      " 23  sexo                    977884 non-null  object\n",
      " 24  marca_veiculo           977884 non-null  object\n",
      " 25  modelo_veiculo          977534 non-null  object\n",
      " 26  ilesos                  977884 non-null  int64 \n",
      " 27  feridos_leves           977884 non-null  int64 \n",
      " 28  feridos_graves          977884 non-null  int64 \n",
      " 29  mortos                  977884 non-null  int64 \n",
      " 30  latitude                977884 non-null  object\n",
      " 31  longitude               977884 non-null  object\n",
      "dtypes: int64(8), object(24)\n",
      "memory usage: 238.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_prf_2017_2023 = pd.read_excel('data/acidentes2013-2023.xlsx')\n",
    "\n",
    "df_prf_2017_2023.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 152203 entries, 0 to 152202\n",
      "Data columns (total 32 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   data_inversa            152203 non-null  object \n",
      " 1   dia_semana              152203 non-null  object \n",
      " 2   horario                 152203 non-null  object \n",
      " 3   uf                      152203 non-null  object \n",
      " 4   br                      152203 non-null  int64  \n",
      " 5   km                      152203 non-null  object \n",
      " 6   municipio               152203 non-null  object \n",
      " 7   causa_acidente          152203 non-null  object \n",
      " 8   tipo_acidente           152203 non-null  object \n",
      " 9   classificacao_acidente  152203 non-null  object \n",
      " 10  fase_dia                152203 non-null  object \n",
      " 11  sentido_via             152203 non-null  object \n",
      " 12  condicao_metereologica  152203 non-null  object \n",
      " 13  tipo_pista              152203 non-null  object \n",
      " 14  tracado_via             152203 non-null  object \n",
      " 15  uso_solo                152203 non-null  object \n",
      " 16  id_veiculo              152203 non-null  int64  \n",
      " 17  tipo_veiculo            152203 non-null  object \n",
      " 18  marca                   152203 non-null  object \n",
      " 19  ano_fabricacao_veiculo  152203 non-null  int64  \n",
      " 20  tipo_envolvido          152203 non-null  object \n",
      " 21  estado_fisico           152203 non-null  object \n",
      " 22  idade                   152203 non-null  int64  \n",
      " 23  sexo                    152203 non-null  object \n",
      " 24  ilesos                  152203 non-null  int64  \n",
      " 25  feridos_leves           152203 non-null  int64  \n",
      " 26  feridos_graves          152203 non-null  int64  \n",
      " 27  mortos                  152203 non-null  int64  \n",
      " 28  latitude                152203 non-null  float64\n",
      " 29  longitude               152203 non-null  float64\n",
      " 30  marca_veiculo           152203 non-null  object \n",
      " 31  modelo_veiculo          152139 non-null  object \n",
      "dtypes: float64(2), int64(8), object(22)\n",
      "memory usage: 37.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_prf_2024 = pd.read_excel('data/acidentes2024.xlsx')\n",
    "\n",
    "df_prf_2024.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prf_2024.to_json(\"data/acidentes2024.json\", orient=\"records\", indent=4, force_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulando Texto e Atributos Categóricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Factorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste = df_prf_2017_2023.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforma em numérico, porem os algorítimos de ML, nao podem medir a distancia entre uma categoria e outra\n",
    "fase_dia_cat = df_teste['fase_dia']\n",
    "fase_dia_cat_encoded, fase_dia_categories = fase_dia_cat.factorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['plena_noite', 'amanhecer', 'pleno_dia', 'anoitecer'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fase_dia_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 3, 3, 0], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fase_dia_cat_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OneHot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<977884x4 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 977884 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder()\n",
    "fase_dia_cat_1hot = encoder.fit_transform(fase_dia_cat_encoded.reshape(-1,1))\n",
    "fase_dia_cat_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fase_dia_cat_1hot.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder \n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "fase_dia_cat_reshaped = fase_dia_cat.values.reshape(-1, 1)\n",
    "fase_dia_cat_1hot = ordinal_encoder.fit_transform(fase_dia_cat_reshaped)\n",
    "fase_dia_cat_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['amanhecer', 'anoitecer', 'plena_noite', 'pleno_dia'], dtype=object)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal_encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusterização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Processamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checando variáveis categóricas\n",
    "variaveis_categoricas = ['municipio', 'uf','causa_acidente','tipo_acidente', 'classificacao_acidente', 'fase_dia', 'sentido_via', 'uso_solo', 'estado_fisico', 'tipo_envolvido', 'marca', 'tipo_pista' ]\n",
    "\n",
    "for variavel in variaveis_categoricas:\n",
    "  print(variavel, df_prf_2017_2023[variavel].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prf_2017_2023 = df_prf_2017_2023.dropna(subset=['ilesos', \"feridos_leves\", \"feridos_graves\", \"mortos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_within_brazil(lat, lon):\n",
    "    return -33.7422 <= lat <= 5.2718 and -73.989 <= lon <= -34.793\n",
    "\n",
    "def encoding(df):\n",
    "    label = LabelEncoder()\n",
    "    for c in df.select_dtypes(\"object\"):\n",
    "        df[c] = df[c].astype(str)\n",
    "        df[c]=label.fit_transform(df[c])\n",
    "    return df\n",
    "\n",
    "def imputation(df):\n",
    "    df = df.fillna(df.median())\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "def preprocessing(df):\n",
    "    df = encoding(df)\n",
    "    df = imputation(df) \n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def calcular_gravidade(row):\n",
    "    if row['ilesos'] == 1:\n",
    "        return 1\n",
    "    elif row['feridos_leves'] == 1:\n",
    "        return 2\n",
    "    elif row['feridos_graves'] == 1:\n",
    "        return 3\n",
    "    elif row['mortos'] == 1:\n",
    "        return 4\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def calcular_fase_dia(row):\n",
    "    if row['fase_dia'] == 'plena_noite':\n",
    "        return 1\n",
    "    elif row['fase_dia'] == 'amanhecer':\n",
    "        return 2\n",
    "    elif row['fase_dia'] == 'pleno_dia':\n",
    "        return 3\n",
    "    elif row['fase_dia'] == 'anoitecer':\n",
    "        return 4\n",
    "    \n",
    "def calcular_condicao_metereologica(row):\n",
    "    if row['condicao_metereologica'] == 'ceu_claro':\n",
    "        return 1\n",
    "    elif row['condicao_metereologica'] == 'vento':\n",
    "        return 2\n",
    "    elif row['condicao_metereologica'] == 'sol':\n",
    "        return 3\n",
    "    elif row['condicao_metereologica'] == 'nublado':\n",
    "        return 4\n",
    "    if row['condicao_metereologica'] == 'garoa_chuvisco':\n",
    "        return 5\n",
    "    elif row['condicao_metereologica'] == 'chuva':\n",
    "        return 6\n",
    "    elif row['condicao_metereologica'] == 'nevoeiro_neblina':\n",
    "        return 7\n",
    "    elif row['condicao_metereologica'] == 'granizo':\n",
    "        return 8\n",
    "    elif row['condicao_metereologica'] == 'neve':\n",
    "        return 9\n",
    "\n",
    "def calcular_tipo_pista(row):\n",
    "    if row['tipo_pista'] == 'simples':\n",
    "        return 1\n",
    "    elif row['tipo_pista'] == 'dupla':\n",
    "        return 2\n",
    "    elif row['tipo_pista'] == 'multipla':\n",
    "        return 3\n",
    "\n",
    "    \n",
    "def calcular_tipo_acidente(row):\n",
    "    if row['tipo_acidente'] == 'eventos_atipicos':\n",
    "        return 1\n",
    "    elif row['tipo_acidente'] == 'danos_eventuais':\n",
    "        return 2\n",
    "    elif row['tipo_acidente'] == 'derramamento_de_carga':\n",
    "        return 3\n",
    "    elif row['tipo_acidente'] == 'tombamento':\n",
    "        return 4\n",
    "    if row['tipo_acidente'] == 'atropelamento_de_pedestre':\n",
    "        return 5\n",
    "    elif row['tipo_acidente'] == 'queda_de_ocupante_de_veiculo':\n",
    "        return 6\n",
    "    elif row['tipo_acidente'] == 'engavetamento':\n",
    "        return 7\n",
    "    elif row['tipo_acidente'] == 'saida_de_leito_carrocavel':\n",
    "        return 8\n",
    "    elif row['tipo_acidente'] == 'atropelamento_de_animal':\n",
    "        return 9\n",
    "    elif row['tipo_acidente'] == 'colisao_lateral_mesmo_sentido':\n",
    "        return 10\n",
    "    if row['tipo_acidente'] == 'colisao_lateral_sentido_oposto':\n",
    "        return 11\n",
    "    elif row['tipo_acidente'] == 'colisao_com_objeto':\n",
    "        return 12\n",
    "    elif row['tipo_acidente'] == 'colisao_com_objeto_estatico':\n",
    "        return 13\n",
    "    elif row['tipo_acidente'] == 'colisao_com_objeto_em_movimento':\n",
    "        return 14\n",
    "    if row['tipo_acidente'] == 'colisao_transversal':\n",
    "        return 15\n",
    "    elif row['tipo_acidente'] == 'colisao_lateral':\n",
    "        return 16\n",
    "    elif row['tipo_acidente'] == 'colisao_traseira':\n",
    "        return 17\n",
    "    elif row['tipo_acidente'] == 'colisao_frontal':\n",
    "        return 18\n",
    "    elif row['tipo_acidente'] == 'capotamento':\n",
    "        return 19\n",
    "    elif row['tipo_acidente'] == 'incendio':\n",
    "        return 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Valores únicos ilesos')\n",
    "for ileso in df_prf_2017_2023[\"ilesos\"].unique():\n",
    "    print(ileso)\n",
    "\n",
    "print('Valores únicos feridos_leves')\n",
    "for ferido_leve in df_prf_2017_2023[\"feridos_leves\"].unique():\n",
    "    print(ferido_leve)\n",
    "\n",
    "print('Valores únicos feridos_graves')\n",
    "for ferido_grave in df_prf_2017_2023[\"feridos_graves\"].unique():\n",
    "    print(ferido_grave)\n",
    "\n",
    "print('Valores únicos mortos')\n",
    "for morto in df_prf_2017_2023[\"mortos\"].unique():\n",
    "    print(morto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prf_2017_2023['longitude'] = df_prf_2017_2023['longitude'].str.replace(\",\", \".\").astype(float).round(6)\n",
    "df_prf_2017_2023['latitude'] = df_prf_2017_2023['latitude'].str.replace(\",\", \".\").astype(float).round(6)\n",
    "\n",
    "df_prf_2017_2023 = df_prf_2017_2023[df_prf_2017_2023.apply(lambda row: is_within_brazil(row['latitude'], row['longitude']), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prf_2017_2023['gravidade'] = df_prf_2017_2023.apply(calcular_gravidade, axis=1)\n",
    "df_prf_2017_2023 = df_prf_2017_2023[df_prf_2017_2023['gravidade'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prf_2017_2023['tipo_acidente'] = df_prf_2017_2023.apply(calcular_tipo_acidente, axis=1)\n",
    "df_prf_2017_2023['tipo_pista'] = df_prf_2017_2023.apply(calcular_tipo_pista, axis=1)\n",
    "df_prf_2017_2023['condicao_metereologica'] = df_prf_2017_2023.apply(calcular_condicao_metereologica, axis=1)\n",
    "df_prf_2017_2023['fase_dia'] = df_prf_2017_2023.apply(calcular_fase_dia, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prf_2017_2023[\"tipo_acidente\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prf_2017_2023[\"tipo_pista\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prf_2017_2023[\"condicao_metereologica\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prf_2017_2023[\"fase_dia\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prf_2017_2023 = preprocessing(df_prf_2017_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prf_2017_2023.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class_4, count_class_1, count_class_3, count_class_2 = df_prf_2017_2023['gravidade'].value_counts()\n",
    "\n",
    "df_class_1 = df_prf_2017_2023[df_prf_2017_2023['gravidade'] == 1]\n",
    "df_class_2 = df_prf_2017_2023[df_prf_2017_2023['gravidade'] == 2]\n",
    "df_class_3 = df_prf_2017_2023[df_prf_2017_2023['gravidade'] == 3]\n",
    "df_class_4 = df_prf_2017_2023[df_prf_2017_2023['gravidade'] == 4]\n",
    "\n",
    "df_class_1_under = df_class_1.sample(count_class_2,random_state=42)\n",
    "df_class_4_under = df_class_4.sample(count_class_2,random_state=42)\n",
    "df_class_3_under = df_class_3.sample(count_class_2,random_state=42)\n",
    "df_under = pd.concat([df_class_1_under, df_class_2, df_class_3_under, df_class_4_under], axis=0)\n",
    "\n",
    "df_class_2_over = df_class_2.sample(count_class_1, replace=True, random_state=42)\n",
    "df_class_3_over = df_class_3.sample(count_class_1, replace=True, random_state=42)\n",
    "df_class_4_over = df_class_4.sample(count_class_1, replace=True, random_state=42)\n",
    "df_over = pd.concat([df_class_1, df_class_2_over, df_class_3_over, df_class_4_over], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_set = df_over.select_dtypes(include=['float64', 'int64', 'int32'])\n",
    "df_to_set = df_to_set.drop([\"marca\", \"uso_solo\", \"modelo_veiculo\", \"gravidade4\", \"estado_fisico\", \"mortos\", \"feridos_graves\", \"feridos_leves\", \"ilesos\", \"dia_semana\", \"data_inversa\", \"horario\", \"municipio\", \"classificacao_acidente\", \"fase_dia\", \"id_veiculo\", \"tipo_envolvido\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste = df_prf_2017_2023.copy()\n",
    "df_teste = df_teste.drop(['classificacao_acidente','ilesos','feridos_leves','feridos_graves', 'mortos', 'estado_fisico', 'marca'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste = df_teste.select_dtypes(include=['float64', 'int64', 'int32'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressao Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logistic_regression = df_teste.copy()\n",
    "\n",
    "# split X, y\n",
    "X_lr = df_logistic_regression.drop('gravidade', axis=1)\n",
    "y_lr = df_logistic_regression['gravidade']\n",
    "\n",
    "scaler_lr = StandardScaler()\n",
    "X_scaled_lr = scaler_lr.fit_transform(X_lr)\n",
    "\n",
    "# split train, test\n",
    "X_train_lr, X_test_lr, y_train_lr, y_test_lr = train_test_split(X_scaled_lr, y_lr, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(max_iter=4000)  # Ajuste 'max_iter' para garantir a convergência\n",
    "model_lr.fit(X_train_lr, y_train_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = model_lr.predict(X_test_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test_lr, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_lr = confusion_matrix(y_test_lr, y_pred_lr)\n",
    "\n",
    "disp_lr = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_lr, display_labels=model_lr.classes_)\n",
    "disp_lr.plot(cmap='Greens')\n",
    "plt.title(\"Matriz de Confusão\")\n",
    "plt.show()\n",
    "\n",
    "#Classe Negativa (Verdadeiro Negativo - VN)\tVN\tFP (Falso Positivo)\n",
    "#Classe Positiva (Falso Negativo - FN)\tFN\tVP (Verdadeiro Positivo)\n",
    "\n",
    "# Verdadeiros Positivos (VP): Casos corretamente classificados como positivos.\n",
    "# Verdadeiros Negativos (VN): Casos corretamente classificados como negativos.\n",
    "# Falsos Positivos (FP): Casos negativos classificados erroneamente como positivos (tipo I).\n",
    "# Falsos Negativos (FN): Casos positivos classificados erroneamente como negativos (tipo II).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_lr, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretação do Gráfico\n",
    "# Curva mais próxima do canto superior esquerdo:\n",
    "\n",
    "# Indica um modelo com melhor capacidade de separação entre as classes.\n",
    "# AUC próximo de 1:\n",
    "\n",
    "# Significa que o modelo tem excelente desempenho.\n",
    "# AUC próximo de 0.5:\n",
    "\n",
    "# Indica que o modelo não tem poder discriminativo (equivalente ao chute aleatório).\n",
    "# Avaliação prática:\n",
    "\n",
    "# Se o AUC é alto, mas o modelo ainda comete muitos erros, verifique os dados (desbalanceamento, qualidade) ou ajuste o limiar de decisão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## floresta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = df_teste.copy()\n",
    "\n",
    "# split X, y\n",
    "X_rf = df_rf.drop('gravidade', axis=1)\n",
    "y_rf = df_rf['gravidade']\n",
    "\n",
    "# scaler_rf = StandardScaler()\n",
    "# X_scaled_rf = scaler_rf.fit_transform(X_rf)\n",
    "\n",
    "# split train, test\n",
    "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_rf, y_rf, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,  # Número de árvores na floresta\n",
    "    max_depth=None,    # Profundidade máxima das árvores\n",
    "    random_state=42,   # Para resultados reprodutíveis\n",
    "    class_weight='balanced'  # Ajusta peso das classes automaticamente\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train_rf, y_train_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf.predict(X_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Matriz de Confusão:\")\n",
    "\n",
    "confusion_matrix_rf = confusion_matrix(y_test_rf, y_pred_rf)\n",
    "\n",
    "disp_rf = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_rf, display_labels=rf.classes_)\n",
    "disp_rf.plot(cmap='Greens')\n",
    "plt.title(\"Matriz de Confusão\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy = ', accuracy_score(y_test_rf, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test_rf, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "for feature, importance in zip(X_rf.columns, importances):\n",
    "    print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter o array bidimensional para unidimensional\n",
    "importances = importances.ravel()\n",
    "\n",
    "# Criar um DataFrame com as features e suas importâncias\n",
    "importances_df = pd.DataFrame({\n",
    "    'Feature': X_rf.columns,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "# Filtrar apenas as features com importância maior que zero\n",
    "importances_df = importances_df[importances_df['Importance'] > 0]\n",
    "\n",
    "# Ordenar as features pela importância (do maior para o menor)\n",
    "importances_df = importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Selecionar as 10 maiores importâncias\n",
    "top_10_importances = importances_df.head(30)\n",
    "\n",
    "# Plotar o gráfico de barras\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_10_importances['Feature'], top_10_importances['Importance'], color='green')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Top 30 Feature Importances')\n",
    "plt.gca().invert_yaxis()  # Inverter o eixo Y para ter as maiores importâncias no topo\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necessárias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['idade', 'horario', 'latitude', 'longitude', 'modelo_veiculo', 'km', 'id_veiculo', 'data_inversa', 'municipio', 'ano_fabricacao_veiculo', 'causa_acidente', 'tipo_veiculo', 'marca_veiculo', 'br', 'dia_semana', 'tracado_via', 'uf', 'uso_solo', 'tipo_envolvido', 'sentido_via', 'sexo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Carregar os dados\n",
    "# Substitua 'seu_dataset.csv' pelo caminho para o seu arquivo\n",
    "df_rna = df_prf.copy()\n",
    "df_rna = df_rna.select_dtypes(include=['float64', 'int64', 'int32'])\n",
    "\n",
    "#df_rna = df_rna[colunas_importanes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rna = df_rna.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suponha que 'target' é a coluna de rótulos e o restante são as features\n",
    "X_rna = df_rna[features]                  # Features\n",
    "y_rna = df_rna['gravidade']              # Classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Pré-processamento dos dados\n",
    "# Dividir o conjunto em treino e teste\n",
    "X_train_rna, X_test_rna, y_train_rna, y_test_rna = train_test_split(X_rna, y_rna, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar as features (padrão necessário para redes neurais)\n",
    "# scaler_rna = StandardScaler()\n",
    "# X_train_rna = scaler_rna.fit_transform(X_train_rna)\n",
    "# X_test_rna = scaler_rna.transform(X_test_rna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se o problema for de classificação com múltiplas classes, fazer one-hot encoding\n",
    "num_classes_rna = len(np.unique(y_rna))  # Número de classes\n",
    "\n",
    "# Ajustar os rótulos para começar de 0 (se necessário)\n",
    "y_train_rna = y_train_rna - y_train_rna.min()\n",
    "y_test_rna = y_test_rna - y_test_rna.min()\n",
    "\n",
    "y_train_rna = to_categorical(y_train_rna, num_classes_rna)\n",
    "y_test_rna = to_categorical(y_test_rna, num_classes_rna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Construir a rede neural\n",
    "model_rna = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_rna.shape[1],)),  # Camada oculta com 64 neurônios\n",
    "    Dense(32, activation='relu'),                                  # Camada oculta com 32 neurônios\n",
    "    Dense(num_classes_rna, activation='softmax' if num_classes_rna > 2 else 'sigmoid')  # Camada de saída\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Compilar o modelo\n",
    "model_rna.compile(\n",
    "    optimizer='adam',                      # Otimizador eficiente\n",
    "    loss='categorical_crossentropy' if num_classes_rna > 2 else 'binary_crossentropy',  # Função de perda\n",
    "    metrics=['accuracy']                   # Métrica de avaliação\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Treinar o modelo\n",
    "history = model_rna.fit(\n",
    "    X_train_rna, y_train_rna,\n",
    "    epochs=50,                # Número de épocas\n",
    "    batch_size=42,            # Tamanho do lote\n",
    "    validation_split=0.3,     # Usar 20% do treino para validação\n",
    "    verbose=1                 # Mostrar progresso\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Avaliar o modelo\n",
    "loss_rna, accuracy_rna = model_rna.evaluate(X_test_rna, y_test_rna)\n",
    "print(f\"\\nLoss: {loss_rna:.4f}, Accuracy: {accuracy_rna:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer previsões\n",
    "y_pred_rna = model_rna.predict(X_test_rna)\n",
    "if num_classes_rna > 2:\n",
    "    y_pred_classes_rna = np.argmax(y_pred_rna, axis=1)  # Converter para rótulos de classe\n",
    "    y_true_classes_rna = np.argmax(y_test_rna, axis=1)\n",
    "else:\n",
    "    y_pred_classes_rna = (y_pred_rna > 0.5).astype(int).flatten()\n",
    "    y_true_classes_rna = y_test_rna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Métricas de desempenho\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "print(confusion_matrix(y_true_classes_rna, y_pred_classes_rna))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_true_classes_rna, y_pred_classes_rna))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Carregar os dados\n",
    "df = df_rna.copy()  # Substitua pelo seu dataset\n",
    "\n",
    "# Pré-processamento\n",
    "# Selecione features relevantes e a variável alvo\n",
    "features = ['idade', 'horario', 'latitude', 'longitude', 'modelo_veiculo', 'km', 'id_veiculo', 'data_inversa', 'municipio', 'ano_fabricacao_veiculo', 'causa_acidente', 'tipo_veiculo', 'marca_veiculo', 'br', 'dia_semana', 'tracado_via', 'uf', 'uso_solo', 'sentido_via', 'sexo']\n",
    "target = 'gravidade'\n",
    "\n",
    "# One-hot encoding para variáveis categóricas\n",
    "# df = pd.get_dummies(df, columns=features, drop_first=True)\n",
    "\n",
    "# Separar X (entrada) e y (saída)\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# Divisão treino/teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalização dos dados\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Criar e treinar a rede neural\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Previsões\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Avaliação\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[features].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalizacao nos dados de treino\n",
    "\n",
    "cross-validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
